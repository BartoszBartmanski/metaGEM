configfile: "config.yaml"

import os
import glob

R1 = sorted([os.path.splitext(val)[0] for val in (glob.glob('/c3se/NOBACKUP/groups/c3-c3se605-19-1/pipeTest/reads/sra/ERR*'))]) #For sample names
#R1 = sorted([os.path.splitext(val)[0] for val in (glob.glob('/c3se/NOBACKUP/users/zorrilla/binning/metabolismPipe/bins_organized/*.fa'))]) #For bin names

R12 = [os.path.splitext(val)[0] for val in R1] #removes filepath (i.e. /c3se/NOBACKUP/groups/c3-c3se605-19-1/pipeTest/reads/sra/)
names = [os.path.basename(val) for val in R12] #removes extension (i.e. .fa)
names = [x[:-2] for x in names] #removes paired end information (i.e. _1 or _2)
names = list(dict.fromkeys(names)) #removes duplicates for sample names, since there are two files with same sample ID (i.e. _1 or _2)

rule all:
    input:
        "kraken2_perBin"
        #"kraken2_raw",
        #"kraken2_perSample",
    output:
        "pipemap.png"
    shell:
        """
        snakemake --dag | dot -Tpng > {output}
        """

rule organizeSubfolders:
    params: names= names
    shell:
        """
        cd /c3se/users/zorrilla/Vera/binningNoBackup/binning/metabolismPipe/bins_organized
        for k in {params.names}; do mkdir -p $k;mv $k*.fa $k; done
        """

rule organizeOnefolder:
    params: names= names
    message: "Organizes bins from CheckM output into one folder without subdirectories. Make sure python variable 'names' is pointing towards sample names."
    shell:
        """
        cd /c3se/users/zorrilla/Vera/binningNoBackup/binning/metabolismPipe/bins_organized
        for k in {params.names}; do mv $k/*.fa .;rm -r $k; done
        """


rule qfilter:
    input:
        R1=config["paths"]["raw_reads"]+"/{ref}_1.fastq.gz",
        R2=config["paths"]["raw_reads"]+"/{ref}_2.fastq.gz"
    output:
        R1="qfiltered/{ref}/{ref}_1.fastq.gz",
        R2="qfiltered/{ref}/{ref}_2.fastq.gz"
    shell:
        """
        fastp --thread 8 -i {input.R1} -I {input.R2} -o {output.R1} -O {output.R2} -j $(dirname {output.R1})/$(echo $( basename $(dirname {output.R1}))).json -h $(dirname {output.R1})/$(echo $( basename $(dirname {output.R1}))).html
        """

rule megahit:
    input:
        R1="qfiltered/{ref}/{ref}_1.fastq.gz",
        R2="qfiltered/{ref}/{ref}_2.fastq.gz"
    output:
        "megahitAssembly/{ref}/final.contigs.fa"
    shell:
        """
        rm -r $(dirname {output})
        megahit -t {config[megahit_params][threads]} --tmp-dir $TMPDIR --presets meta-large --verbose -1 {input.R1} -2 {input.R2} -o {config[paths][concoct_run]}/$(dirname {output})
        rm -r $(dirname {output})/intermediate_contigs
        """

rule cutcontigs:
    input:
        "megahitAssembly/{ref}/final.contigs.fa"
    output:
        "contigs/{ref}/megahit_c10K.fa"
    shell:
        """
        set +u;source activate concoct_env;set -u;
        cd $(dirname {input})
        python {config[cutcontigs_params][script_dir]} -c 10000 -o 0 -m $(basename {input}) > $(basename {output});
        mv $(basename {output}) {config[paths][concoct_run]}/$(dirname {output});
        cd {config[paths][concoct_run]}
        #tar -cvf {output} megahitAssembly/ #NEED THESE FOR CHECKM FILTERING!!!
        """

rule kallistoBuild:
    input:
        "contigs/{ref}/megahit_c10K.fa"
    output:
        "quantification/kallistoIndices/{ref}.kaix"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        kallisto index {input} -i {output}
        """

rule gatherIndexes:
    input:
        expand("quantification/kallistoIndices/{ref}.kaix", ref = names)
    output:
        "quantification/kallistoIndices/indexDummy.txt"
    shell:
        """
        touch {output}
        """

rule kallistoQuant:
    input:
        R1=config["paths"]["concoct_run"]+"/qfiltered/{names}/{names}_1.fastq.gz",
        R2=config["paths"]["concoct_run"]+"/qfiltered/{names}/{names}_2.fastq.gz",
        index="quantification/kallistoIndices/{ref}.kaix",
        indexDummy="quantification/kallistoIndices/indexDummy.txt",
    output:
        "quantification/ref_{ref}/{names}/abundance.tsv.gz"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        cd $TMPDIR
        kallisto quant --threads {config[kallisto_params][threads]} --plaintext -i {config[paths][concoct_run]}/{input.index} -o $TMPDIR {input.R1} {input.R2}
        gzip abundance.tsv
        cp $(basename {output}) {config[paths][concoct_run]}/$(dirname {output})
        cp run_info.json {config[paths][concoct_run]}/$(dirname {output})
        rm $(basename {output})
        rm run_info.json
        cd {config[paths][concoct_run]}
        """

rule gatherAbundance:
    input:
        expand("quantification/ref_{ref}/{names}/abundance.tsv.gz",ref=names, names=names)
    output:
        "quantification/quantDummy.txt"
    shell:
        """
        touch {output}
        """

rule kallisto2concoctTable:
    input:
        abundances = lambda wildcards: expand("quantification/ref_{ref}/{{names}}/abundance.tsv.gz".format(ref=wildcards.concoct), names = names),
        abdunaceDummy= "quantification/quantDummy.txt"
    output:
        "concoct_input/{concoct}_concoct_inputtableR.tsv"
    params:
        files= names
    shell:
        """
        set +u;source activate concoct_env;set -u;
        python {config[kallisto_params][script]} \
            --samplenames <(for s in {params.files}; do echo $s; done) \
                {input.abundances} > {output}
        """

rule concoct:
    input:
        table="concoct_input/{names}_concoct_inputtableR.tsv",
        comp="contigs/{names}/megahit_c10K.fa"
    output:
        "concoct_output/{names}/clustering_gt1000.csv"
    shell:
        """
        set +u;source activate concoct_env;set -u;
        cd {config[paths][concoct_run]};
        concoct --coverage_file {input.table} --composition_file {input.comp} -b $(dirname {output}) -t {config[concoct_params][threads]} -c {config[concoct_params][clusters]}
        cut -d"," -f2 $(dirname {output})/clustering_gt1000.csv | sort | uniq -c | wc > $(dirname {output})/binfo.txt
        """

rule mergeClustering:
    input:
        "concoct_output/{names}/clustering_gt1000.csv"
    output:
        "concoct_output/{names}/clustering_merged.csv"
    shell:
        """
        set +u;source activate concoct_env;set -u;
        merge_cutup_clustering.py {input} > {output}
        """

rule extractBins:
    input:
        clustering="concoct_output/{names}/clustering_merged.csv",
        OGcontigs="megahitAssembly/{names}/final.contigs.fa"
    output:
        "bins/{names}"
    shell:
        """
        set +u;source activate concoct_env;set -u;
        mkdir -p {output}
        extract_fasta_bins.py {input.OGcontigs} {input.clustering} --output_path {output}
        """

rule checkM:
    input:
        "bins/{names}"
    output:
        "checkm_out/{names}/lineage.ms"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        checkm lineage_wf --tmpdir $TMPDIR -x fa -t {config[checkM_params][threads]} --pplacer_threads {config[checkM_params][threads]} {input} $(dirname {output})
        """

rule checkMtable:
    input:
        "checkm_out/{names}/lineage.ms"
    output:
        "checkm_out/{names}/binTable.txt"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        checkm qa --tmpdir $TMPDIR --tab_table $(dirname {output})/lineage.ms $(dirname {output}) > {output}
        """

rule binFilter:
    input:
        bins= "bins/{names}",
        table= "checkm_out/{names}/binTable.txt"
    output:
        "bins_filtered/{names}"
    shell:
        """
        mkdir -p {output}
        {config[checkM_params][filterScript]} {input.bins} {input.table} {output} --min_completeness {config[checkM_params][comp]} --max_contamination {config[checkM_params][cont]}
        """

rule zipBins:
    input:
        expand("bins/{names}", names=names)
    output:
        "bins.tar.gz"
    shell:
        """
        tar -zcvf {output} bins/
        """

rule kraken2raw:
    input:
        reads="/c3se/NOBACKUP/groups/c3-c3se605-19-1/perSamplePipe/qfiltered/",
    output:
        classified="kraken2_raw"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        #cp -r {input.reads} $TMPDIR
        cp -r {config[kraken2_params][db]} $TMPDIR
        cd $TMPDIR
        mkdir -p kraken2_raw
        for sample in /c3se/NOBACKUP/groups/c3-c3se605-19-1/perSamplePipe/qfiltered/*;do
            kraken2 --db KRAKEN2_DB --threads 2 --paired --unclassified-out kraken2_raw/$(basename $sample).unclassified# --classified-out kraken2_raw/$(basename $sample).classified# --report kraken2_raw/$(basename $sample).kreport --use-names $sample/*.fastq.gz
        done
        cp -r {output} {config[paths][concoct_run]}
        cd {config[paths][concoct_run]}
        """

rule brackenRaw:
    input:
        report="kraken2_raw/{names}/krakenReport.txt"
    output:
        "kraken2_raw/{names}/brackenReport.txt"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        bracken -d {config[kraken2_params][db]} -i {input.report} -o {output}
        """

rule kraken2perSample:
    input:
        binsFilt="/c3se/NOBACKUP/users/zorrilla/binning/metabolismPipe/bins_organized",
    output:
        "kraken2_out"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        cp -r {config[kraken2_params][db]} $TMPDIR
        cp -r {input.binsFilt} $TMPDIR
        cd $TMPDIR
        mkdir -p kraken2_out
        for sample in bins_organized/*;do
            kraken2 --db KRAKEN2_DB --threads 64 --unclassified-out kraken2_out/$(basename $sample).unclassified --classified-out kraken2_out/$(basename $sample).classified --report kraken2_out/$(basename $sample).kreport --use-names $sample/*.fa
        done
        cp -r {output} {config[paths][concoct_run]}
        cd {config[paths][concoct_run]}
        """

rule brackenPerSample:
    input:
        report="kraken2_perSample/{names}/{names}.kreport--use-names"
    output:
        "kraken2_perSample/{names}/brackenReport.txt"
    shell:
        """
        set +u;source activate checkm_env;set -u;
        bracken -d {config[kraken2_params][db]} -i {input.report} -o {output}
        """

rule kraken2perBin:
    input:
        binsFilt="/c3se/NOBACKUP/users/zorrilla/binning/metabolismPipe/bins_organized",
    output:
        "kraken2_perBin"
    message: "Make sure that folder 'bins_organized/' has all fasta files without sample subdirectories. This can be done by running rule 'organizeOnefolder'."
    shell:
        """
        set +u;source activate checkm_env;set -u;
        cp -r {config[kraken2_params][db]} $TMPDIR
        cp -r {input.binsFilt} $TMPDIR
        cd $TMPDIR
        mkdir -p kraken2_perBin
        for bin in bins_organized/*;do
            kraken2 --db KRAKEN2_DB --threads 2 --unclassified-out kraken2_perBin/$(basename $bin).unclassified --classified-out kraken2_perBin/$(basename $bin).classified --report kraken2_perBin/$(basename $bin).kreport --use-names $bin
        done
        cp -r {output} {config[paths][concoct_run]}
        cd {config[paths][concoct_run]}
        """

                            #BELOW ARE RULES USEFUL FOR EXTRACTING BINS USING MY OWN R SCRIPT, NO LONGER USED

#rule parseFASTA:
#    input:"evaluation-output/clustering_gt1000_scg.tab"
#    output: "speciesProt"#dynamic("carvemeOut/{speciesProt}.txt"),dynamic("speciesDNA/{speciesDNA}.txt")
#    shell:
#        """
#        cd {config[paths][concoct_run]}
#        mkdir -p {config[speciesProt_params][dir]}
#        cp {input} {config[paths][concoct_run]}/{config[speciesProt_params][dir]}
#        cd {config[speciesProt_params][dir]}
#        sed -i '1d' {config[speciesProt_params][infile]} #removes first row
#        awk '{{print $2}}' {config[speciesProt_params][infile]} > allspecies.txt #extracts node information
#        sed '/^>/ s/ .*//' {config[speciesDNA_params][FASTA]} > {config[speciesDNA_params][FASTAcleanID]} #removes annotation to gene ID
#        sed '/^>/ s/ .*//' {config[speciesProt_params][pFASTA]} > {config[speciesProt_params][pFASTAcleanID]} #removes annotation to protein ID
#        Rscript {config[speciesProt_params][scriptdir]}multiFASTA2speciesFASTA.R
#        sed -i 's/"//g' species*
#        sed -i '/k99/s/^/>/' species*
#        sed -i 's/{config[speciesProt_params][tab]}/{config[speciesProt_params][newline]}/' species*
#        sed -i '1d' speciesDNA* #remove first row
#        sed -i '1d' speciesDNA* #remove second row
#        cd {config[paths][concoct_run]}
#        """

#rule pseudoProt:
#    input: "speciesProt"
#    output: dynamic("carvemeOut/{speciesProt}.txt")
#    shell:
#        """
#        cd {config[paths][concoct_run]}
#        mkdir -p {config[carveme_params][dir]}
#        cd {config[carveme_params][dir]}
#        cp {config[paths][concoct_run]}/{config[speciesProt_params][dir]}/speciesProt*.txt {config[paths][concoct_run]}/{config[carveme_params][dir]}
#        find . -name "species*.txt" -size -{config[carveme_params][cutoff]} -delete #delete files with little information, these cause trouble
#        cd {config[paths][concoct_run]}
#        """

#rule pseudoDNA:
#    input: "speciesProt"
#    output: dynamic("speciesDNA/{speciesDNA}.fa")
#    shell:
#        """
#        cd {config[paths][concoct_run]}
#        mkdir -p {config[speciesDNA_params][dir]}
#        cp {config[speciesProt_params][dir]}/speciesDNA*.txt {config[paths][concoct_run]}/{config[speciesDNA_params][dir]}
#        cp {config[speciesProt_params][dir]}/cleanID.fa {config[paths][concoct_run]}/{config[speciesDNA_params][dir]}
#        cd {config[speciesDNA_params][dir]}
#        find . -name "species*.txt" -size -{config[speciesDNA_params][cutoff]} -delete #delete files with little information, these cause trouble
#        for file in *.txt; do
#            mv "$file" "$(basename "$file" .txt).fa"
#        done
#        cd {config[paths][concoct_run]}
#        """

#rule requiredRule:
#    input: dynamic("speciesDNA/{speciesDNA}.txt")
#    output: "requiredDummyFile"
#    shell: "cd {config[paths][concoct_run]} ;touch {output}"



                ##BELOW ARE THE RULES FOR GENERATING BOWTIE INDEX, BOWTIE ALLIGNMENT, AND COVTABLE

#rule bowtieBuild:
#    input:"contigs/{names}/megahit_c10K.fa"
#    output:"contigs/{names}/buildDummy.txt"
#    shell:
#        """
#        set +u;source activate concoct_env;set -u;
#        cd $(dirname {input});
#        bowtie2-build $(basename {input}) $(basename {input});
#        cd {config[paths][concoct_run]};
#        touch {output}
#        """

#rule bowtie:
#    input:
#        assembly="contigs/{names}/megahit_c10K.fa",
#        reads=config["paths"]["raw_reads"]+"/{names}_1.fastq",
#        index= "contigs/{names}/buildDummy.txt"
#    output:"map/{names}"
#    shell:
#        """
#        set +u;source activate concoct_env;set -u;
#        export MRKDUP={config[bowtie_params][MRKDUP_jardir]};
#        DIRECTORY={output}
#        if [ ! -d "$DIRECTORY" ]; then
#            mkdir -p {output}
#            cd {output};
#            bash {config[bowtie_params][MRKDUP_shelldir]} -c -t {config[bowtie_params][threads]} -p '-q' {input.reads} $(echo {input.reads} | sed s/_1.fastq/_2.fastq/) pair {config[paths][concoct_run]}/{input.assembly} asm bowtie2;
#            cd {config[paths][concoct_run]};
#        fi
#        """
#rule covtable:
#    input: "map/{names}"
#    output:"concoct-input/{names}/concoct_inputtable.tsv"
#    shell:
#        """
#        set +u;source activate concoct_env;set -u;
#        cd {config[paths][concoct_run]}/{input}
#        python {config[paths][CONCOCT]}/scripts/gen_input_table.py --isbedfiles \
#            --samplenames <(for s in ERR*; do echo $s | cut -d'_' -f1; done) \
#            ../contigs/{names}/megahit_c10K.fa */bowtie2/asm_pair-smds.coverage > concoct_inputtable.tsv;
#        mkdir -p {config[paths][concoct_run]}/concoct_input/{names};
#        mv concoct_inputtable.tsv {config[paths][concoct_run]}/concoct_input/{names};
#        """


#rule kraken2wilcard:
#    input:
#        binsFilt="/c3se/NOBACKUP/users/zorrilla/binning/metabolismPipe/bins_organized/{names}",
#        #binZip="bins.tar.gz"
#    output:
#        classified="kraken2_out/{names}/classified",
#        unclassified="kraken2_out/{names}/unclassified",
#        report="kraken2_out/{names}/krakenReport.txt"
#    shell:
#        """
#        set +u;source activate checkm_env;set -u;
#        cp -r {config[kraken2_params][db]} $TMPDIR
#        cp -r {input.binsFilt} $TMPDIR
#        cd $TMPDIR
#        kraken2 --db KRAKEN2_DB --threads 64 --unclassified-out {output.unclassified} --classified-out {output.classified} --report {output.report} --use-names bins_organized/$(basename {input.binsFilt})/*
#        cd kraken2_out
#        cp -r $(basename $(dirname {output.classified})) {config[paths][concoct_run]}/kraken2_out
#        cd {config[paths][concoct_run]}
#        """
